{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f121b3b-47e0-4ba4-aeff-9931238c0a2b",
   "metadata": {},
   "source": [
    "# Prediction on your own molecules\n",
    "\n",
    "This notebook assume that you have docked complexes of your molecules docked with METLL3. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26911f0b-56d5-4645-916a-416c5240540c",
   "metadata": {},
   "source": [
    "# Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358a4cb3-3b8e-41e6-b01e-8e21696631db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from oddt.fingerprints import PLEC\n",
    "import oddt\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import os\n",
    "import tempfile\n",
    "from openbabel import openbabel\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Subset,TensorDataset\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "# Evaluate metrics on the test set\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, average_precision_score, matthews_corrcoef\n",
    "import deepchem as dc\n",
    "from deepchem.utils.vina_utils import prepare_inputs\n",
    "from deepchem.utils import download_url, load_from_disk\n",
    "from deepchem.feat import RdkitGridFeaturizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5206b5c-4cd1-4465-b510-021333e22642",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4ba1fa-d5b8-47dc-9fe3-565be77f65f8",
   "metadata": {},
   "source": [
    "# Define function for voxel features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460fd7cf-4420-4e90-933f-0f22f5d2905e",
   "metadata": {},
   "outputs": [],
   "source": [
    "protein = '/home/juni/working/mettl3/notebooks/Attention_4DCNN/example/receptor.pdb'\n",
    "featurizer = RdkitGridFeaturizer(box_width=24,voxel_width = 6, feature_types = [\"splif\"], ecfp_power = 9, splif_power = 9, flatten = False, verbose = False)\n",
    "def extract_grid_feature(ligand_file):\n",
    "    feature = featurizer._featurize((ligand_file, protein))\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bea6886-ab3b-4cb8-9ec6-f4e45a41bc41",
   "metadata": {},
   "source": [
    "# Generate voxel features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797f5c1d-d169-4416-ac8e-cba9c4bda4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/juni/working/mettl3/notebooks/Attention_4DCNN/example/docked_complexes/')\n",
    "docked_sdf_active = glob.glob('*.sdf')\n",
    "docked_sdf_active.sort(key=lambda x: int(''.join(filter(str.isdigit, x))))\n",
    "\n",
    "screening_features = Parallel(n_jobs = 60, backend = \"multiprocessing\")(delayed(extract_grid_feature)(mol) for mol in tqdm(docked_sdf_active))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2dd83aa-3664-4a1d-a586-437ee234c818",
   "metadata": {},
   "source": [
    "# Create a DataLoader for the screening molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfa34a1-0289-4981-bb7a-b790fa83e6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_features = torch.tensor(screening_features, dtype=torch.float32)\n",
    "input_features = input_features.permute(0, 4, 1, 2, 3)\n",
    "screening_dataset = TensorDataset(input_features)  # No target values\n",
    "screening_loader = DataLoader(screening_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc6bf27-7f67-4374-beca-2d8dc86dd1ff",
   "metadata": {},
   "source": [
    "# Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2744db40-aece-42e9-87da-b4a8032f57f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MultiheadAttention3D(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads):\n",
    "        super(MultiheadAttention3D, self).__init__()\n",
    "        self.multihead_attn = nn.MultiheadAttention(embed_dim, num_heads)\n",
    "        self.norm = nn.LayerNorm(embed_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Reshape (batch_size, channels, D, H, W) -> (batch_size, channels, D*H*W)\n",
    "        batch_size, channels, D, H, W = x.shape\n",
    "        x = x.view(batch_size, channels, -1).permute(2, 0, 1)  # Shape: (D*H*W, batch_size, channels)\n",
    "\n",
    "        # Apply Multihead Attention\n",
    "        attn_output, _ = self.multihead_attn(x, x, x)\n",
    "        attn_output = self.norm(attn_output)\n",
    "\n",
    "        # Reshape back to (batch_size, channels, D, H, W)\n",
    "        attn_output = attn_output.permute(1, 2, 0).view(batch_size, channels, D, H, W)\n",
    "        return attn_output\n",
    "\n",
    "class CNN3D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN3D, self).__init__()\n",
    "        # Input shape: (batch_size, 1539, 4, 4, 4)\n",
    "        self.conv1 = nn.Conv3d(1536, 32, kernel_size=3, stride=1, padding=1)  # Output: (batch_size, 512, 4, 4, 4)\n",
    "        self.bn1 = nn.BatchNorm3d(32)\n",
    "\n",
    "        #self.attn1 = MultiheadAttention3D(embed_dim=32, num_heads=1)  # Apply Multihead Attention\n",
    "        self.attn_layers = nn.ModuleList([MultiheadAttention3D(embed_dim=32, num_heads=8) for _ in range(6)])  # Apply Multihead Attention with 6 layers\n",
    "        self.conv2 = nn.Conv3d(32, 64, kernel_size=3, stride=1, padding=1)  # Output: (batch_size, 256, 4, 4, 4)\n",
    "        self.bn2 = nn.BatchNorm3d(64)\n",
    "\n",
    "        self.attn2 = MultiheadAttention3D(embed_dim=64, num_heads=8)  # Apply Multihead Attention\n",
    "\n",
    "        self.conv3 = nn.Conv3d(64, 128, kernel_size=3, stride=1, padding=1)  # Output: (batch_size, 128, 4, 4, 4)\n",
    "        self.bn3 = nn.BatchNorm3d(128)\n",
    "\n",
    "        self.attn3 = MultiheadAttention3D(embed_dim=128, num_heads=8)  # Apply Multihead Attention\n",
    "\n",
    "        self.pool = nn.MaxPool3d(kernel_size=2, stride=2, padding=0)  # Output: (batch_size, 128, 2, 2, 2)\n",
    "        self.dropout_conv = nn.Dropout3d(p=0.5)\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(128 * 2 * 2 * 2, 256)\n",
    "        self.dropout_fc1 = nn.Dropout(p=0.5)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.dropout_fc2 = nn.Dropout(p=0.5)\n",
    "        self.fc3 = nn.Linear(128, 1)  # Binary classification (e.g., active/inactive)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))  # Conv1 + BatchNorm + ReLU\n",
    "        #Apply 6 layers of Multihead Attention sequentially\n",
    "        for attn_layer in self.attn_layers:\n",
    "             x = attn_layer(x)\n",
    "        #x = self.attn1(x)  # Multihead Attention after conv1\n",
    "\n",
    "        x = F.relu(self.bn2(self.conv2(x)))  # Conv2 + BatchNorm + ReLU\n",
    "        #x = self.attn2(x)  # Multihead Attention after conv2\n",
    "\n",
    "        x = F.relu(self.bn3(self.conv3(x)))  # Conv3 + BatchNorm + ReLU\n",
    "        #x = self.attn3(x)  # Multihead Attention after conv3\n",
    "\n",
    "        x = self.dropout_conv(x)  # Dropout after convolutions\n",
    "        x = self.pool(x)  # Pooling layer\n",
    "\n",
    "        x = x.view(x.size(0), -1)  # Flatten the output\n",
    "        x = F.relu(self.fc1(x))  # Fully connected layer 1\n",
    "        x = self.dropout_fc1(x)  # Dropout after fc1\n",
    "        x = F.relu(self.fc2(x))  # Fully connected layer 2\n",
    "        x = self.dropout_fc2(x)  # Dropout after fc2\n",
    "        x = torch.sigmoid(self.fc3(x))  # Sigmoid for binary classification\n",
    "        #x = self.fc3(x)  # No activation function for regression\n",
    "        return x\n",
    "# Example usage:\n",
    "model = CNN3D()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0486897a-6796-4582-acd4-aa0512c88bf3",
   "metadata": {},
   "source": [
    "# Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71952ac-a402-4d3d-bd1c-309c1b50f4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN3D()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68e19ef-10af-48ea-be24-5923a8ea4b44",
   "metadata": {},
   "source": [
    "# Define the path to the saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5470c8c-9c0f-4ba9-898c-e72d73ea43a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "save_dir = '/home/juni/working/mettl3/notebooks/Attention_4DCNN/models/'  # Ensure this matches the directory where you saved the model\n",
    "save_path = os.path.join(save_dir, 'model_checkpoint_predict_100epochs.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b40164-e03b-4c8c-8917-47684b1202cd",
   "metadata": {},
   "source": [
    "# Load the saved checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf08971-67b6-4480-b5f0-641b5854555a",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0453c0e2-b7c7-44c1-a5ec-6b46c78c7d6f",
   "metadata": {},
   "source": [
    "# Load the model state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31336ce-cbca-4d22-afa8-f6d604313fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e42f282-afd8-405b-a254-3c9b9eeb847c",
   "metadata": {},
   "source": [
    "# Load the optimizer state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ddabca-d8dd-4c29-a44e-84fa53123fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-4)\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c32b5a-8675-48f5-8636-7976b477c5e9",
   "metadata": {},
   "source": [
    "# Set the model to evaluation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5d4282-93a2-4145-8356-8370af843838",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173827df-878f-4df1-b31a-addb9e682203",
   "metadata": {},
   "source": [
    "# Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19cd326-7769-41d0-ac33-ab629520db99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# Lists to store predictions\n",
    "predicted_scores = []\n",
    "predicted_classes = []\n",
    "\n",
    "# Define a threshold (for binary classification)\n",
    "threshold = 0.5\n",
    "\n",
    "# Run predictions\n",
    "with torch.no_grad():\n",
    "    for inputs in screening_loader:\n",
    "        inputs = inputs[0].to(device)  # Inputs from the DataLoader\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Convert outputs to numpy and flatten\n",
    "        scores = outputs.cpu().numpy().astype(float).flatten()  # Flatten to remove extra brackets\n",
    "        classes = (scores >= threshold).astype(int)  # Convert scores to classes based on threshold\n",
    "\n",
    "        predicted_scores.extend(scores.tolist())  # Convert to list\n",
    "        predicted_classes.extend(classes.tolist())  # Convert to list\n",
    "\n",
    "# Convert predictions to a DataFrame\n",
    "screening_results = pd.DataFrame({\n",
    "    \"Predicted_score\": predicted_scores,\n",
    "    \"Predicted_class\": predicted_classes\n",
    "})\n",
    "\n",
    "# Save predictions to a CSV file\n",
    "screening_results.to_csv(\"./screening_results.csv\", index=False)\n",
    "\n",
    "print(\"Predictions for screening molecules saved to 'screening_results.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b4e469-b4e6-4fca-970f-6c8daa21e7d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18f1dc4-968a-4921-9f77-bdd96e99177e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b106d3-0d8e-43c6-8bae-99c5fa18db2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8ba5e4-7d79-46ba-af9d-04281e4db960",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
