{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8bc99016-88d3-47f5-a1af-ddc81fb9f2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem.MolStandardize import rdMolStandardize\n",
    "from rdkit.Chem.Scaffolds import MurckoScaffold\n",
    "from itertools import accumulate, chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8ead02d-b2cc-46b3-ba08-2ab4114da3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Path to data CSV file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "60b8f14f-7517-4aff-96b4-fc4d2937e67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_mol(mol):\n",
    "    clean_mol = rdMolStandardize.Cleanup(mol)\n",
    "    parent_mol = rdMolStandardize.FragmentParent(clean_mol)\n",
    "    uncharger = rdMolStandardize.Uncharger()\n",
    "    uncharged_mol = uncharger.uncharge(parent_mol)\n",
    "    return uncharged_mol\n",
    "\n",
    "def get_canonical_smiles(mol):\n",
    "    return Chem.MolToSmiles(mol, isomericSmiles=True, canonical=True)\n",
    "\n",
    "def find_duplicates(smiles_df, smiles_col='smiles', id_col='cid'):\n",
    "    canonical_smiles_dict = {}\n",
    "    duplicates = []\n",
    "    unique_smiles_with_ids = []\n",
    "\n",
    "    for index, row in smiles_df.iterrows():\n",
    "        id = row[id_col]\n",
    "        smiles = row[smiles_col]\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        \n",
    "        if mol is not None:\n",
    "            std_mol = standardize_mol(mol)\n",
    "            canonical_smiles = get_canonical_smiles(std_mol)\n",
    "            \n",
    "            if canonical_smiles in canonical_smiles_dict:\n",
    "                # Append the ID of the duplicate\n",
    "                duplicates.append((id, canonical_smiles_dict[canonical_smiles]))\n",
    "            else:\n",
    "                # Store the unique SMILES along with its ID\n",
    "                unique_smiles_with_ids.append((id, canonical_smiles))\n",
    "                canonical_smiles_dict[canonical_smiles] = id\n",
    "\n",
    "    return unique_smiles_with_ids, duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f2c9de5-4817-440b-837f-15a9a7e458d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_smiles, duplicates = find_duplicates(data, smiles_col='smiles', id_col='cid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8347b2d4-de0c-47e5-988b-01c1f155948b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The number of unique smiles is {len(unique_smiles)}')\n",
    "print(f'The number of duplicates smiles is {len(duplicates)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c4686f8c-2618-4f2c-b1ac-8321b06b8eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import f1_score,average_precision_score\n",
    "\n",
    "def scaffold_split(data, smiles_col, test_size = 0.2,random_state = 42):\n",
    "    \"\"\"\n",
    "    Split a molecule dataset into training and test sets based on scaffolds.\n",
    "\n",
    "    Parameters:\n",
    "    - data (pd.DataFrame): The dataset containing molecule data.\n",
    "    - smiles_col (str): The name of the column containing SMILES strings.\n",
    "    - test_size (float): Proportion of the dataset to include in the test split.\n",
    "    - random_state (int): Random state for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "    - data_train (pd.DataFrame): Training set.\n",
    "    - data_test (pd.DataFrame): Test set.\n",
    "    \"\"\"\n",
    "    scaffolds = {}\n",
    "    for idx, row in data.iterrows():\n",
    "        smiles = row[smiles_col]\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        scaffold = MurckoScaffold.MurckoScaffoldSmiles(mol=mol, includeChirality=False)\n",
    "        if scaffold not in scaffolds:\n",
    "            scaffolds[scaffold] = [idx]\n",
    "        else:\n",
    "            scaffolds[scaffold].append(idx)\n",
    "\n",
    "    scaffold_lists = list(scaffolds.values())\n",
    "    np.random.seed(random_state)\n",
    "    np.random.shuffle(scaffold_lists)\n",
    "\n",
    "    num_molecules = len(data)\n",
    "    num_test = int(np.floor(test_size * num_molecules))\n",
    "    train_idx, test_idx = [], []\n",
    "    for scaffold_list in scaffold_lists:\n",
    "        if len(test_idx) + len(scaffold_list) <= num_test:\n",
    "            test_idx.extend(scaffold_list)\n",
    "        else:\n",
    "            train_idx.extend(scaffold_list)\n",
    "\n",
    "    data_train = data.iloc[train_idx]\n",
    "    data_test = data.iloc[test_idx]\n",
    "\n",
    "    return data_train, data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a02f385-74e9-45ed-a4ba-7281ac2c8b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_test = scaffold_split(combine_df, 'smiles', random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ba6d97-de90-4ed6-b221-8acdb09aa34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrames to CSV files\n",
    "data_train.to_csv('Path to csv data_train.csv', index=False)\n",
    "data_test.to_csv('Path to csv data_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582ee4af-952b-41b5-9c77-08f77c1fcd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "mol_train = [Chem.MolFromSmiles(x) for x in data_train['smiles']]\n",
    "mol_test= [Chem.MolFromSmiles(x) for x in data_test['smiles']]\n",
    "\n",
    "\n",
    "fp_train= [AllChem.GetMorganFingerprintAsBitVect(x,radius=2,nBits=2048) for x in mol_train]\n",
    "\n",
    "fp_test= [AllChem.GetMorganFingerprintAsBitVect(x,radius=2,nBits=2048) for x in mol_test]\n",
    "\n",
    "\n",
    "size_x= len(fp_train)\n",
    "size_y= len(fp_test)\n",
    "\n",
    "print(size_x)\n",
    "print(size_y)\n",
    "\n",
    "\n",
    "similarity_matrix = np.zeros((size_y, size_x))\n",
    "similarity_matrix.shape\n",
    "\n",
    "idx = 0\n",
    "np_fps = list()\n",
    "for fp in fp_test:\n",
    "    np_fp = np.zeros((1,))\n",
    "    Chem.DataStructs.ConvertToNumpyArray(fp, np_fp)\n",
    "    np_fps.append(np_fp)\n",
    "    # Calculate Tanimoto similarity\n",
    "    similarity = Chem.DataStructs.BulkTanimotoSimilarity(fp, fp_train)\n",
    "    # Save it to similarity matrix\n",
    "    similarity_matrix[idx] = similarity\n",
    "    idx += 1\n",
    "\n",
    "\n",
    "df_similarity = pd.DataFrame(similarity_matrix)\n",
    "\n",
    "df_similarity = pd.DataFrame(similarity_matrix)\n",
    "df_similarity.columns = list(data_train['mol_id'])\n",
    "df_similarity.index = data_test['mol_id']\n",
    "df_similarity\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set(rc={'figure.figsize':(11.7,8.27)})\n",
    "fig, ax = plt.subplots(dpi=300, figsize=(7,5))\n",
    "ax = sns.heatmap(df_similarity, vmin=0, vmax=1,\n",
    "                yticklabels=False, xticklabels=False,cmap=\"coolwarm\")\n",
    "ax.set_xlabel(\"Train\", fontsize = 15)\n",
    "ax.set_ylabel(\"Test\", fontsize = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48063744-50a1-420f-86e9-d800beea89fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract upper triangle values excluding the diagonal\n",
    "tanimoto_coefficients = np.array(similarity_matrix)[np.triu_indices_from(np.array(similarity_matrix), k=1)]\n",
    "\n",
    "# Define the ranges for Tanimoto coefficients\n",
    "ranges = np.arange(0, 1.1, 0.1)\n",
    "accumulated_proportion = []\n",
    "\n",
    "# Calculate accumulated proportion for each range\n",
    "for i in ranges:\n",
    "    proportion = np.sum(tanimoto_coefficients < i) / len(tanimoto_coefficients)\n",
    "    accumulated_proportion.append(proportion)\n",
    "\n",
    "# Create a single figure\n",
    "fig, ax_tanimoto = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Plotting the data\n",
    "ax_tanimoto.plot(ranges, accumulated_proportion, 'o-', color='blue', linewidth=2, markersize=8, label='Accumulated Proportion')\n",
    "\n",
    "# Set axis labels with larger font size\n",
    "ax_tanimoto.set_xlabel('Tanimoto Coefficients Range', fontsize=16, fontweight='bold')\n",
    "ax_tanimoto.set_ylabel('Accumulated Proportion', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Set the title with larger font size\n",
    "ax_tanimoto.set_title('Tanimoto Coefficients Between Training and Test Active Scaffold', \n",
    "          fontsize=18, fontweight='bold')\n",
    "\n",
    "# Customize x-ticks (improved formatting)\n",
    "x_labels = [f'[{i:.1f}, {i + 0.1:.1f})' for i in np.arange(0, 1, 0.1)] + ['[1.0, 1.0]']\n",
    "ax_tanimoto.set_xticks(ranges)\n",
    "ax_tanimoto.set_xticklabels(x_labels, rotation=45, ha='right', fontsize=14, color='black')\n",
    "\n",
    "# Customize y-ticks\n",
    "ax_tanimoto.tick_params(axis='y', labelsize=14, colors='black')\n",
    "\n",
    "# Add grid lines for better readability\n",
    "ax_tanimoto.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "# Add black borders to all four sides\n",
    "for spine in ax_tanimoto.spines.values():\n",
    "    spine.set_edgecolor('black')\n",
    "    spine.set_linewidth(2)\n",
    "\n",
    "# Customize major ticks (improved consistency)\n",
    "ax_tanimoto.tick_params(axis='both', which='major', direction='in', length=8, width=2, colors='black')\n",
    "\n",
    "# Add a legend\n",
    "ax_tanimoto.legend(fontsize=14, loc='lower right')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f31d5e2-1247-495b-9044-897386d91079",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaffolds = {}\n",
    "for idx, smi in zip(data_train['cid'],data_train['smiles']):\n",
    "    mol = Chem.MolFromSmiles(smi)\n",
    "    scaffold = MurckoScaffold.MurckoScaffoldSmiles(mol=mol, includeChirality=False)\n",
    "    if scaffold not in scaffolds:\n",
    "        scaffolds[scaffold] = [idx]\n",
    "    else:\n",
    "        scaffolds[scaffold].append(idx)\n",
    "\n",
    "dfscaffolds = pd.DataFrame(list(scaffolds.items()), columns=['scaffold', 'cid'])\n",
    "dfscaffolds.to_csv('/home/juni/working/mettl3/train_scaffolds.csv', index=False)\n",
    "dfscaffolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37c4252-7645-4bb7-a1a4-62c77a6c84f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaffolds = {}\n",
    "for idx, smi in zip(data_test['cid'],data_test['smiles']):\n",
    "    mol = Chem.MolFromSmiles(smi)\n",
    "    scaffold = MurckoScaffold.MurckoScaffoldSmiles(mol=mol, includeChirality=False)\n",
    "    if scaffold not in scaffolds:\n",
    "        scaffolds[scaffold] = [idx]\n",
    "    else:\n",
    "        scaffolds[scaffold].append(idx)\n",
    "\n",
    "dfscaffolds = pd.DataFrame(list(scaffolds.items()), columns=['scaffold', 'cid'])\n",
    "dfscaffolds.to_csv('/home/juni/working/mettl3/test_scaffolds.csv', index=False)\n",
    "dfscaffolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea402b8-b643-4bc3-96ee-f398105fe65e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
